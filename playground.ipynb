{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5hjCcLDr2WC",
        "outputId": "ccc60f0c-fd78-4dbe-8598-0512d1036aad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1089k  100 1089k    0     0  4029k      0 --:--:-- --:--:-- --:--:-- 4064k\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!curl https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt > shakespeare.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O6medjfRsLD9"
      },
      "outputs": [],
      "source": [
        "# read it in to inspect it\n",
        "with open('shakespeare.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWI_VyAsN8F",
        "outputId": "ed819dd0-72e5-40a6-d2ed-928ff73bfda6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5V0FvqseE0",
        "outputId": "25ca7adc-b8c0-42d1-b08c-e0863c5c314e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-Rbyr8sfM8",
        "outputId": "f34e94a9-5b44-4cf3-885b-986731929109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Simple Tokenizer using char->int mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46, 43, 50, 50, 53]\n",
            "hello \n"
          ]
        }
      ],
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)} # simple mapping from set of unique chars\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]  # encode function to lookup the stoi dict\n",
        "decode = lambda i: ''.join([itos[x] for x in i])  #decode func to lookup the itos dict\n",
        "\n",
        "print(encode('hello'))\n",
        "print(decode(encode('hello ')))  # 2-way check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Encode the entire dataset, using our tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Also split the dataset into train-val\n",
        "n = int(0.9 * len(data))  # 90-10 split\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Batching of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[60, 43, 56, 63,  1, 56, 53, 53],\n",
            "        [ 1, 39, 50, 50,  1, 61, 47, 58],\n",
            "        [ 7, 40, 56, 43, 43, 42, 47, 52],\n",
            "        [47, 45, 46, 40, 53, 59, 56,  1]])\n",
            "\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 56, 63,  1, 56, 53, 53, 58],\n",
            "        [39, 50, 50,  1, 61, 47, 58, 46],\n",
            "        [40, 56, 43, 43, 42, 47, 52, 45],\n",
            "        [45, 46, 40, 53, 59, 56,  1, 51]])\n",
            "---------------\n",
            "when input is [60], target is 43\n",
            "when input is [60, 43], target is 56\n",
            "when input is [60, 43, 56], target is 63\n",
            "when input is [60, 43, 56, 63], target is 1\n",
            "when input is [60, 43, 56, 63, 1], target is 56\n",
            "when input is [60, 43, 56, 63, 1, 56], target is 53\n",
            "when input is [60, 43, 56, 63, 1, 56, 53], target is 53\n",
            "when input is [60, 43, 56, 63, 1, 56, 53, 53], target is 58\n",
            "when input is [1], target is 39\n",
            "when input is [1, 39], target is 50\n",
            "when input is [1, 39, 50], target is 50\n",
            "when input is [1, 39, 50, 50], target is 1\n",
            "when input is [1, 39, 50, 50, 1], target is 61\n",
            "when input is [1, 39, 50, 50, 1, 61], target is 47\n",
            "when input is [1, 39, 50, 50, 1, 61, 47], target is 58\n",
            "when input is [1, 39, 50, 50, 1, 61, 47, 58], target is 46\n",
            "when input is [7], target is 40\n",
            "when input is [7, 40], target is 56\n",
            "when input is [7, 40, 56], target is 43\n",
            "when input is [7, 40, 56, 43], target is 43\n",
            "when input is [7, 40, 56, 43, 43], target is 42\n",
            "when input is [7, 40, 56, 43, 43, 42], target is 47\n",
            "when input is [7, 40, 56, 43, 43, 42, 47], target is 52\n",
            "when input is [7, 40, 56, 43, 43, 42, 47, 52], target is 45\n",
            "when input is [47], target is 45\n",
            "when input is [47, 45], target is 46\n",
            "when input is [47, 45, 46], target is 40\n",
            "when input is [47, 45, 46, 40], target is 53\n",
            "when input is [47, 45, 46, 40, 53], target is 59\n",
            "when input is [47, 45, 46, 40, 53, 59], target is 56\n",
            "when input is [47, 45, 46, 40, 53, 59, 56], target is 1\n",
            "when input is [47, 45, 46, 40, 53, 59, 56, 1], target is 51\n"
          ]
        }
      ],
      "source": [
        "# The dataset is divided on basis of 2 dimensions. Time Dimension and Batch Size.\n",
        "# Time dimension is basically the context length. How many tokens our model sees before it predicts the next token.\n",
        "# Karpathy says it as block_size.\n",
        "# The Batch Dimension or Batch size is just no. of independent sequences the model will train on parallely(right word?)\n",
        "# basically the batch size in a mini batch gradient descent, nothing else.\n",
        "\n",
        "block_size = 8\n",
        "batch_size = 4\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a mini batch of inputs, targets\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - batch_size, (batch_size,))\n",
        "    x = torch.stack([data[i:block_size+i] for i in ix])\n",
        "    y = torch.stack([data[i+1:block_size+i+1] for i in ix])\n",
        "    return x,y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"\\ntargets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "# The logic behind these inputs-targets is that elements in target array, are the next token of the elements in inputs.\n",
        "# visualization\n",
        "print('---------------')\n",
        "\n",
        "for b in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = xb[b,: t+1]\n",
        "        target = yb[b,t]\n",
        "\n",
        "        print(f'when input is {context.tolist()}, target is {target}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simplest Language Model: Bigram LM.\n",
        "1. works with pairs of characters next to each other\n",
        "2. learns the probability distribution of which character has higher probability of appearing with the given character\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([256, 65])\n",
            "tensor(4.6581, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Kh-SssOQrk\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BigramLM(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # directly reads off the probability for next token \n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets = None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "    \n",
        "m = BigramLM(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=10)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.361586093902588\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "optim = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for _ in range(10000):\n",
        "    xb, yb = get_batch('train')\n",
        "    # get the output and the loss\n",
        "    logits, loss = m(xb,yb)\n",
        "\n",
        "    optim.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hay t yous IKI inoaqusen makeses I'd beuce?\n",
            "S:\n",
            "Bowir hovesthtonge m hed cithithavoif f bs, ve, gure;\n"
          ]
        }
      ],
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [0., 1., 1.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.triu(torch.ones(3,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-7.8009e-01,  2.0357e-01,  8.8040e-01,  5.2806e-01,  2.8297e-01,\n",
              "           8.6944e-01, -2.2371e-01, -3.7576e-01, -7.6070e-01,  5.0455e-01,\n",
              "           1.9049e-01, -6.4040e-02,  1.0003e-01,  6.8179e-01,  4.3075e-01,\n",
              "           4.9797e-02],\n",
              "         [-2.8999e-01,  1.2600e-01,  2.4025e-01,  2.4115e-01,  1.6343e-01,\n",
              "           3.3082e-01, -1.3248e-01, -9.1101e-02, -3.1777e-01,  1.1215e-01,\n",
              "           1.0715e-01,  3.3474e-02,  9.9169e-03,  1.8785e-01,  1.7111e-01,\n",
              "           1.1418e-02],\n",
              "         [-5.1117e-01,  4.2295e-01,  7.6118e-02,  6.0407e-01,  5.2052e-01,\n",
              "           6.1353e-01, -4.3035e-01,  3.3322e-02, -6.9974e-01, -1.0325e-01,\n",
              "           3.3389e-01,  2.8762e-01, -9.1352e-02,  6.9303e-02,  3.4544e-01,\n",
              "          -8.1848e-03],\n",
              "         [-3.9075e-01,  4.3407e-01, -1.3337e-01,  5.6046e-01,  5.2607e-01,\n",
              "           4.8576e-01, -4.3751e-01,  1.3240e-01, -6.1188e-01, -2.4489e-01,\n",
              "           3.3520e-01,  3.4593e-01, -1.2985e-01, -9.1402e-02,  2.8822e-01,\n",
              "          -2.1869e-02],\n",
              "         [ 3.5771e-01, -9.9915e-02, -3.9235e-01, -2.4800e-01, -1.3736e-01,\n",
              "          -3.9968e-01,  1.0902e-01,  1.6597e-01,  3.5339e-01, -2.2152e-01,\n",
              "          -9.2093e-02,  2.1888e-02, -4.2310e-02, -3.0408e-01, -1.9895e-01,\n",
              "          -2.1908e-02],\n",
              "         [-3.7940e-01,  3.5670e-01, -1.7489e-02,  4.8647e-01,  4.3585e-01,\n",
              "           4.6185e-01, -3.6134e-01,  6.6032e-02, -5.4910e-01, -1.4074e-01,\n",
              "           2.7871e-01,  2.6217e-01, -9.0984e-02, -4.3267e-03,  2.6572e-01,\n",
              "          -1.2105e-02],\n",
              "         [-5.5692e-02,  1.5543e-01, -1.8083e-01,  1.6326e-01,  1.8326e-01,\n",
              "           8.3391e-02, -1.5405e-01,  1.0920e-01, -1.5225e-01, -1.7510e-01,\n",
              "           1.1533e-01,  1.5580e-01, -6.9206e-02, -1.3500e-01,  6.1495e-02,\n",
              "          -1.6306e-02],\n",
              "         [-4.2439e-01,  4.8267e-01, -1.6428e-01,  6.1872e-01,  5.8436e-01,\n",
              "           5.2927e-01, -4.8618e-01,  1.5464e-01, -6.7237e-01, -2.8280e-01,\n",
              "           3.7217e-01,  3.8849e-01, -1.4711e-01, -1.1391e-01,  3.1549e-01,\n",
              "          -2.5335e-02]],\n",
              "\n",
              "        [[ 1.4042e+00, -9.2120e-01, -6.2524e-01, -1.4449e+00, -1.1514e+00,\n",
              "          -1.6489e+00,  9.4636e-01,  1.4077e-01,  1.7549e+00, -7.6907e-02,\n",
              "          -7.4345e-01, -5.1619e-01,  1.2056e-01, -5.0404e-01, -8.9640e-01,\n",
              "          -1.1434e-02],\n",
              "         [ 2.8370e-01,  5.9023e-01, -1.4690e+00,  3.9992e-01,  6.6582e-01,\n",
              "          -2.1569e-01, -5.6961e-01,  7.7796e-01, -1.8508e-01, -1.1788e+00,\n",
              "           4.1033e-01,  7.7937e-01, -3.9632e-01, -1.1139e+00, -1.1716e-02,\n",
              "          -1.1174e-01],\n",
              "         [-1.1303e+00,  6.1839e-01,  7.1631e-01,  1.0534e+00,  7.8431e-01,\n",
              "           1.3087e+00, -6.4110e-01, -2.3222e-01, -1.3271e+00,  2.4645e-01,\n",
              "           5.0953e-01,  2.7534e-01, -3.0310e-02,  5.6629e-01,  6.9471e-01,\n",
              "           2.6564e-02],\n",
              "         [ 1.0474e+00, -6.7993e-01, -4.7879e-01, -1.0714e+00, -8.5050e-01,\n",
              "          -1.2289e+00,  6.9884e-01,  1.1194e-01,  1.3040e+00, -6.8134e-02,\n",
              "          -5.4934e-01, -3.7685e-01,  8.6030e-02, -3.8533e-01, -6.6705e-01,\n",
              "          -9.5414e-03],\n",
              "         [-5.6665e-01,  2.6451e-01,  4.3777e-01,  4.8753e-01,  3.4054e-01,\n",
              "           6.4920e-01, -2.7681e-01, -1.6034e-01, -6.3364e-01,  1.9172e-01,\n",
              "           2.2259e-01,  8.6250e-02,  9.4562e-03,  3.4319e-01,  3.3834e-01,\n",
              "           1.9730e-02],\n",
              "         [ 3.3313e-01, -2.4874e-01, -9.6119e-02, -3.6971e-01, -3.0810e-01,\n",
              "          -3.9577e-01,  2.5411e-01,  4.2486e-03,  4.3733e-01,  2.6993e-02,\n",
              "          -1.9818e-01, -1.5683e-01,  4.4962e-02, -8.0223e-02, -2.1925e-01,\n",
              "           1.5432e-03],\n",
              "         [ 1.3286e+00, -8.9857e-01, -5.4504e-01, -1.3912e+00, -1.1206e+00,\n",
              "          -1.5643e+00,  9.2184e-01,  1.0720e-01,  1.6792e+00, -3.2422e-02,\n",
              "          -7.2290e-01, -5.1908e-01,  1.2866e-01, -4.4182e-01, -8.5405e-01,\n",
              "          -7.0230e-03],\n",
              "         [ 8.1020e-01, -6.7641e-01, -1.1019e-01, -9.6283e-01, -8.3201e-01,\n",
              "          -9.7336e-01,  6.8803e-01, -5.8650e-02,  1.1133e+00,  1.7271e-01,\n",
              "          -5.3357e-01, -4.6275e-01,  1.4807e-01, -1.0197e-01, -5.4883e-01,\n",
              "           1.3825e-02]],\n",
              "\n",
              "        [[ 2.8223e-01, -2.9897e-02, -3.9419e-01, -1.5206e-01, -5.1744e-02,\n",
              "          -3.0794e-01,  3.8060e-02,  1.7819e-01,  2.4481e-01, -2.4810e-01,\n",
              "          -3.7328e-02,  7.2970e-02, -5.9899e-02, -3.0370e-01, -1.4630e-01,\n",
              "          -2.4183e-02],\n",
              "         [ 1.5725e-01, -1.4645e-01,  4.8431e-03, -2.0039e-01, -1.7903e-01,\n",
              "          -1.9121e-01,  1.4840e-01, -2.6025e-02,  2.2661e-01,  5.6246e-02,\n",
              "          -1.1451e-01, -1.0707e-01,  3.6956e-02, -1.9908e-05, -1.0983e-01,\n",
              "           4.8210e-03],\n",
              "         [-3.9502e-01,  1.0503e+00, -1.1923e+00,  1.1115e+00,  1.2394e+00,\n",
              "           5.8359e-01, -1.0415e+00,  7.2416e-01, -1.0436e+00, -1.1638e+00,\n",
              "           7.8034e-01,  1.0457e+00, -4.6259e-01, -8.8946e-01,  4.2479e-01,\n",
              "          -1.0830e-01],\n",
              "         [ 3.5856e-01, -3.1596e-01, -2.0042e-02, -4.4091e-01, -3.8744e-01,\n",
              "          -4.3328e-01,  3.2077e-01, -4.1990e-02,  5.0424e-01,  1.0132e-01,\n",
              "          -2.4813e-01, -2.2370e-01,  7.4528e-02, -2.3476e-02, -2.4651e-01,\n",
              "           8.4594e-03],\n",
              "         [-4.1393e-01,  2.4932e-01,  2.2277e-01,  4.0613e-01,  3.1368e-01,\n",
              "           4.8272e-01, -2.5718e-01, -6.2966e-02, -5.0187e-01,  5.5992e-02,\n",
              "           2.0310e-01,  1.2686e-01, -2.3489e-02,  1.7757e-01,  2.5940e-01,\n",
              "           6.5051e-03],\n",
              "         [ 2.1034e-01, -3.1651e-01,  2.1509e-01, -3.7553e-01, -3.7907e-01,\n",
              "          -2.7402e-01,  3.1671e-01, -1.5126e-01,  3.8697e-01,  2.5597e-01,\n",
              "          -2.4026e-01, -2.8052e-01,  1.1479e-01,  1.5721e-01, -1.7323e-01,\n",
              "           2.3451e-02],\n",
              "         [ 4.5847e-01, -6.2169e-01,  3.5086e-01, -7.5776e-01, -7.4732e-01,\n",
              "          -5.8695e-01,  6.2348e-01, -2.6386e-01,  7.9605e-01,  4.5574e-01,\n",
              "          -4.7444e-01, -5.3381e-01,  2.1325e-01,  2.5375e-01, -3.6270e-01,\n",
              "           4.1501e-02],\n",
              "         [-1.6543e-01,  2.1828e-01, -1.1616e-01,  2.6803e-01,  2.6266e-01,\n",
              "           2.1087e-01, -2.1905e-01,  8.9376e-02, -2.8304e-01, -1.5539e-01,\n",
              "           1.6683e-01,  1.8574e-01, -7.3675e-02, -8.3690e-02,  1.2955e-01,\n",
              "          -1.4124e-02]],\n",
              "\n",
              "        [[-3.2359e-01,  3.9966e-01, -1.7997e-01,  4.9996e-01,  4.8217e-01,\n",
              "           4.0835e-01, -4.0171e-01,  1.4845e-01, -5.3465e-01, -2.6303e-01,\n",
              "           3.0661e-01,  3.3223e-01, -1.2931e-01, -1.2810e-01,  2.4746e-01,\n",
              "          -2.3777e-02],\n",
              "         [ 1.4263e-01,  8.5926e-02, -3.7395e-01,  1.3194e-02,  9.0775e-02,\n",
              "          -1.4033e-01, -7.9778e-02,  1.8759e-01,  5.3486e-02, -2.7677e-01,\n",
              "           5.4084e-02,  1.5188e-01, -8.5017e-02, -2.8518e-01, -5.1887e-02,\n",
              "          -2.6463e-02],\n",
              "         [-4.8429e-01,  4.0772e-01,  5.9991e-02,  5.7855e-01,  5.0126e-01,\n",
              "           5.8233e-01, -4.1459e-01,  3.8337e-02, -6.6782e-01, -1.0833e-01,\n",
              "           3.2139e-01,  2.8047e-01, -9.0347e-02,  5.6520e-02,  3.2880e-01,\n",
              "          -8.7426e-03],\n",
              "         [-4.6452e-01,  4.4669e-01, -3.8642e-02,  6.0450e-01,  5.4516e-01,\n",
              "           5.6698e-01, -4.5217e-01,  9.0464e-02, -6.7922e-01, -1.8724e-01,\n",
              "           3.4843e-01,  3.3233e-01, -1.1679e-01, -1.8283e-02,  3.2751e-01,\n",
              "          -1.6225e-02],\n",
              "         [-8.5713e-02,  9.4672e-02, -2.8317e-02,  1.2246e-01,  1.1477e-01,\n",
              "           1.0647e-01, -9.5439e-02,  2.8519e-02, -1.3384e-01, -5.2905e-02,\n",
              "           7.3136e-02,  7.5264e-02, -2.8189e-02, -1.9342e-02,  6.3105e-02,\n",
              "          -4.7206e-03],\n",
              "         [-5.7667e-01,  4.0497e-01,  2.1069e-01,  6.1715e-01,  5.0370e-01,\n",
              "           6.8123e-01, -4.1477e-01, -3.2084e-02, -7.3924e-01, -8.3460e-03,\n",
              "           3.2456e-01,  2.4233e-01, -6.3951e-02,  1.7226e-01,  3.7395e-01,\n",
              "           9.3928e-04],\n",
              "         [-1.2859e-01,  1.3065e-01, -2.2787e-02,  1.7357e-01,  1.5901e-01,\n",
              "           1.5801e-01, -1.3202e-01,  3.1792e-02, -1.9288e-01, -6.2307e-02,\n",
              "           1.0150e-01,  9.9954e-02, -3.6120e-02, -1.4174e-02,  9.2190e-02,\n",
              "          -5.4769e-03],\n",
              "         [-5.7779e-01,  5.0284e-01,  4.3205e-02,  7.0487e-01,  6.1702e-01,\n",
              "           6.9724e-01, -5.1071e-01,  6.1575e-02, -8.0815e-01, -1.5382e-01,\n",
              "           3.9528e-01,  3.5329e-01, -1.1668e-01,  4.6051e-02,  3.9586e-01,\n",
              "          -1.2743e-02]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "# imagine batch as a single sentence\n",
        "# time defines the number of tokens in the sentence\n",
        "# channels define the data/embeddings belonging to the actual token.\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# self-attention, finally\n",
        "# single head of attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x)  # (B, T, 16)\n",
        "v = value(x)\n",
        "\n",
        "weights = q @ k.transpose(-2,-1)  # (B, T, 16) * (B, 16, T) -> (B, T, T)\n",
        "\n",
        "# weighted aggregation trick. creating a lower triangle of 1s, and matmul with a matrix will give us sort of a mask,\n",
        "# that doesnt allow the model to see the future tokens.\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "weights = weights.masked_fill(tril==0, float('-inf'))\n",
        "weights = F.softmax(weights,dim=-1)\n",
        "\n",
        "output = weights @ v\n",
        "\n",
        "output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = 50257\n",
        "block_size = 256\n",
        "n_embed = 384\n",
        "n_head = 16\n",
        "\n",
        "B,T = 2,8\n",
        "x = torch.randint(0,vocab_size, (B,T))\n",
        "pos = torch.arange(0, T, dtype = torch.long)\n",
        "\n",
        "wte = nn.Embedding(vocab_size, n_embed)\n",
        "wpe = nn.Embedding(block_size, n_embed)\n",
        "c_attn_kv = nn.Linear(n_embed, 2 * n_embed)\n",
        "c_attn_q = nn.Linear(n_embed, n_embed)\n",
        "\n",
        "y = wpe(pos) + wte(x)\n",
        "\n",
        "B, T, C = y.shape\n",
        "\n",
        "kv = c_attn_kv(y)\n",
        "q = c_attn_q(y)\n",
        "\n",
        "# k,v = kv.split(n_embed, dim=2)\n",
        "\n",
        "\n",
        "# q.view(B, T, n_head, C // n_head).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.638400e+08\n"
          ]
        }
      ],
      "source": [
        "print(f'{32768 * 5000:e}') "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
